## 模型

<img src="redis.assets/截屏2021-06-23 21.18.54.png" alt="截屏2021-06-23 21.18.54" style="zoom:200%;" />

## 常见问题

1. redis的五大数据类型底层，分别运用于哪些场景举例说明：

   - string：
     - 缓存
     - 计数
     - session
   - hash：
     - hashMap
   - list：
     - 消息队列
   - set：
     - 交集并集等操作
   - zset：
     - 排行榜
     - 延时队列
     - 优先级队列

2. 高级数据结构：

   1. HyperLogLog：供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV；
      - 
   2. bitMap：位图是支持按 bit 位来存储信息，可以用来实现 **布隆过滤器（BloomFilter）**；
   3. GeoHash：可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。有没有想过用Redis来实现附近的人？或者计算最优地图路径？

3. redis实现分布式锁的几种方式以及相应产生的问题：https://blog.csdn.net/liuyongchen0824/article/details/88341981

   1. incr
   2. setnx
   3. 上述两种方式在加锁后都要设置expire防止没有释放锁，但是expire不是原子操作不能保证事务，所以可以使用`set($key, $value, array('nx', 'ex' => $ttl));`的原子操作。

4. redis为什么是单线程的？io多路复用保证性能；瓶颈在网络io，不在cpu。

5. 多核cpu下是否会造成浪费？是的他是单线程的，但是，我们可以通过在单机开多个**Redis实例**嘛。

6. redis做异步队列：使用list结构作为队列，**rpush**生产消息，**lpop**消费消息。当lpop没有消息的时候，要适当sleep一会再重试；如果不使用sleep，可以直接BLPOP，在没有元素的时候阻塞。

7. redis做发布订阅模式下：

   1. 缺点：当消费者下线的时候，生产的消息丢失。
   2. 在项目中为什么不用redis做发布订阅服务器：因为当订阅客户端下线了，生产消息丢失，不能持久化。

8. 了解延时队列与其使用场景：

   1. 延时队列场景：一般用在订单过期、订单轮询时。
   2. redis如何实现延时队列：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用**zrangebyscore**指令获取N秒之前的数据轮询进行处理。

9. redis持久化的两种方式：rdb和aof，原理、优缺点、触发同步时机

   1. 原理：

      - rdb fork子进程进行io操作；
      - aof：每执行一条指令就通过写指令到aof文件中，也可以设置1s同步一次；采用了追加文件的操作，如果文件过大会触发压缩，和rdb类似，fork一个子进程，然后将子进程中的内存数据通过做成一个个set操作指令写入新的aof文件中。

   2. 优缺点：

      - rdb优点：rdb同步时fork子进程进行io操作，同步性能高，并且rdb恢复速度快；缺点：会丢失更新，并且fork有两倍的内存膨胀。

      - aof优点：同步更新，能保证数据的可靠性；**AOF**的日志是通过一个叫**非常可读**的方式记录的，这样的特性就适合做**灾难性数据误删除**的紧急恢复了，比如公司的实习生通过**flushall**清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份**AOF**日志文件，把最后一条**flushall**命令删了就完事了；           缺点：同步性能低（所以使用aof的时候一般设置1s同步一次），恢复数据慢。

   3. redis策略：当redis启动的时候，如果aof文件存在或者配置文件中redis打开aof，都会优先进行aof的同步。

   4. 日常使用 ：一般使用rdb做数据快速恢复，再用aof做补全操作。

10. pipeline：客户端封装了一批命令，一起发送给服务端执行，是客户端的动作。

    1. 优点：提高了服务端的吞吐量。
    2. 缺点：当通过pipeline提交的查询命令数据较少，可以被内核缓冲区所容纳时，Redis可以保证这些命令执行的原子性。然而一旦数据量过大，超过了内核缓冲区的接收大小，那么命令的执行将会被打断，原子性也就无法得到保证。

11. redis事务：是针对服务端的动作，当读到multi命令的时候，redis会为这个事务生成一个队列，当有命令来的时候，将命令添加到队列中；当读到exec的时候，会将队列中的元素取出一次执行完。redis事务不具备acid特性

    1. 原子性（事务不能回滚）：mysql中回滚操作是通过记录的undolog来实现的，它既保证了事务的回滚，也保证了mvcc事务隔离；而redis的aof日志是在事务中指令执行完后才记录的，所以没有回滚机制。

    2. 一致性：如果仅仅就 ACID 的表述上来说，一致性就是从 A 状态经过事务到达 B 状态没有破坏各种约束性，仅就 Redis 而言不谈实现的业务，那显然就是满意一致性。

       但如果加上业务去谈一致性，例如，A 转账给 B，A 减少 10 块钱，B 增加 10 块钱，因为 Redis 并不具备回滚，也就不具备传统意义上的原子性，所以 Redis 也应该不具备传统的一致性。

    3. 隔离性：能保证，因为是单线程的；mysql通过mvcc。

    4. 持久性：通过一定策略可以保证持久性，rdb和aof。

12. redis中watch与事务配合使用：watch监控一个值，当执行事务的时候会判断此时的值是否与监控的时候的值不一样，如果不一样就认为是其他线程修改了，那么就不会执行事务，用到了乐观锁的概念。解决aba问题：通过加version。

13. redis缓存雪崩：同一时间大量key失效，解决方法：把每个Key的失效时间都加个随机值。

14. 缓存穿透：一直发redis和数据库中都不存在的数据，例如id为-1。

    - 解决方法：1. 在接口上加校验。 2. 当都查不到的时候，可以将这个值的k-v在redis中设置为null，时间短些。3. 布隆过滤器，通过hash判断此时这个值数据库存不存在，如果不存在直接return，存在就去db中查再刷新redis。

15. 缓存击穿：redis一直扛着一个大热点，但是一旦这个热点一失效，大量请求立马就会灌入db。

16. redis主从同步的方式：当从机连接的时候，主机先进行一个rdb快照同步，如何将此时的请求存入缓冲区，将快照发送给从机，从机接受到快照后加载到内存，随后给主机一个响应，主机再将rdb到此时的缓冲区中的数据传给从机，之后就执行一句同步一句。

17. redis如何保证高可用：通过主从集群的方式，配置哨兵   https://blog.csdn.net/zero__007/article/details/86564520

    1. 哨兵数量限制？多少保证高可用？

18. redis并发产生的问题

    1. 减库存问题（先读后写）：使用redis实现分布式锁解决、也可以使用watch乐观锁的方法解决。

19. redis与数据库的数据一致性的问题：

    1. 什么情况下会引入不一致？  当更新数据的时候会引入不一致，此时有两种方式：1是先更新数据库，再删除缓存；2是先删除缓存，再更新数据库。

    2. 第2种情况下如果删除缓存后，更新数据库没有完成就被读了，此时读出来的是旧值并设置到了缓存中，此时造成不一致问题

       > 采用延时双删来解决
       >
       > 1. 线程1删除缓存，然后去更新数据库
       > 2. 线程2来读缓存，发现缓存已经被删除，所以直接从数据库中读取，这时候由于线程1还没有更新完成，所以读到的是旧值，然后把旧值写入缓存
       > 3. 线程1，根据估算的时间，sleep，由于sleep的时间大于线程2读数据+写缓存的时间，所以缓存被再次删除
       > 4. 如果还有其他线程来读取缓存的话，就会再次从数据库中读取到最新值

20. 经典kv-db的读写方式：

    1. 读的时候，先读缓存，如果没有再读数据库，如果存在，那么就读出写入缓存。

    2. 更新数据的时候，先更新数据库，再删除缓存。

       > 为什么是删除缓存？
       >
       > 不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于**比较复杂的缓存数据计算的场景**，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，**这个缓存到底会不会被频繁访问到？**
       >
       > 举个栗子：一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有**大量的冷数据**。
       >
       > 实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。**用到缓存才去算缓存。**
       >
       > 其实删除缓存，而不是更新缓存，就是一个 Lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

21. redis和memcached的区别：

    1. **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
    2. **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。**
    3. **Redis 有灾难恢复机制。** 因为可以把缓存中的数据持久化到磁盘上。
    4. **Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。**
    5. **Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的.**
    6. **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** （Redis 6.0 引入了多线程 IO ）
    7. **Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。**
    8. **Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**

22. redis线程模型：io多路复用，epoll

23. redis过期策略：定期删除和惰性删除

    1. 定期删除：redis将所有设置了过期的数据放入字典中，每隔100ms进行一次扫描（抽取20个扫描），将过期的数据删除，如果过期的数据超过了1/4，就再随机抽20个，这样进行下去。
    2. 惰性删除：当客户端访问这个key的时候，如果这个key过期了，再删除。

24. redis淘汰策略：

    1. noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键

    2. allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键

    3. volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键

    4. allkeys-random：加入键的时候如果过限，从所有key随机删除

    5. volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐

    6. volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键

    7. volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键

    8. allkeys-lfu：从所有键中驱逐使用频率最少的键

    > 如果没有键满足回收的前提条件的话，策略**volatile-lru**, **volatile-random**以及**volatile-ttl**就和noeviction 差不多了。

25. **redis中pipeline、事务、lua理解与区别:**

    1. pipeline：是客户端的概念，客户端每次送一堆过去，redis只管接受再当前线程中执行，其他不保证；也就是说有可能pipeline太大了，在一个socket的接受缓冲区接受不下，也就不能保证在当前线程把这个pipeline一次性执行完。
    2. 事务他就解决了上面pipeline的问题，它是服务端的概念（维护一个队列，在一个线程中执行），但是他又涉及到多次io传输；他同时具有乐观锁的概念，保证了一定的事务特征。
    3. lua脚本可以理解为综合了pipiline和事务的优点，他保证线程一次执行完，但是又不需要事务的多次传输。

26. redis的zset是一种基于跳表的数据结构：

    1. 跳表的概念：一般应用于有序链表的查找/插入过程中，主要解决有序链表查询和插入的时间复杂度问题。

    2. 跳表的实现：redis给每一个要插入的数据随机出一个层数（1-32，50%往下递减），随机出来层数之后，通过跳表找到相应的位置进行插入，并且维护当前层的指针信息；在查询的时候，先走大，再走小。

       > 为什么redis中不用红黑树或者平衡二叉树这种结构？
       >
       > 1. **性能考虑：** 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部 *(下面详细说)*；
       > 2. **实现考虑：** 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；

27. hyperloglog：解决大数据量下的计数统计问题，例如需要统计某个网页的用户（一个用户算一次）访问次数。

    1. 使用hashSet，当用户太多的时候容易发生oom。

    2. 使用bitMap，一个亿用户需要占用12M，一个网页需要12M，那么多个网页也容易溢出。

    3. 使用hyperloglog：

       > 原理：其实就是通过一种大数据下的估算方式（举一个抛硬币，连续20次正面平均下来得抛多少次），hyperloglog就是用了这种思想，分2^14个桶（其实就是取平均），每次送入一个数，计算这个数的后14位，看他在哪个桶；确定桶后然后再看他最后面那个1在哪一位，往那个桶里设置，桶中数据取最大值，最后再加权运算一下，可能会有误差，但是桶的数量够多，平均一下误差就比较小。





































