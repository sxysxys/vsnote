# 计算机网络

1. 7层模型简述，每层干什么，对应什么设备，每一层协议举例子。
2. 输入url对应的过程



### TCP

1. 报文格式，分别是干什么的  端口+发送包id+应答包id+数据偏移+几个状态位+窗口大小+数据
2. tcp三次握手
   - 为什么要三次握手？为什么不是四次或者两次：https://www.jianshu.com/p/864cd33e6bd4
3. tcp四次挥手
4. 状态机：三次握手的信号SYN  ACK的使用；四次挥手信号FIN  ACK；  https://time.geekbang.org/column/article/8975
5. 顺序控制、超时重传策略（定时器和快速重传）
6. 窗口的几个部分：https://time.geekbang.org/column/article/9141  流量控制、拥塞控制；什么时候慢启动、什么时候快速重传
7. tcp brr算法解决的问题：不要等中间所有缓存设备都满了再进行拥塞控制，而是尽量保证高速度。
8. tcp如何保证可靠传输：就是tcp机制的总结
   1. 三次握手保证连接
   2. 端到端的检验和
   3. 收到数据会有ack应答，保证发送接受端都知道这个数据已经传输成功
   4. 顺序发送和超时重传：ARQ协议
   5. 流量控制和拥塞控制



### Socket与各种IO(*)

1. 操作系统socket有哪些api：
   - `bind`：绑定端口
   - `listen`：监听端口
   - `accept()`：接受连接
   - `connect()`：客户端连接服务器
   - `send()`：tcp发送数据
   - `recv()`：tcp接收数据
2. 各种io的概念：
   1. bio：阻塞io
   2. nio：轮询判断数据来了没
   3. io多路复用：一个线程处理多个socket，需要搭配socket的nio使用，理由见epoll。
   4. 信号驱动：当数据来了，发出信号给用户进程，进程再去取出数据。
   5. 异步io：用户线程只需要调api读数据，不管有没有都不会阻塞，接下来操作就交给操作系统，操作系统会将数据读到用户内存中，通知用户线程直接用即可。
3. selector：最初版本io多路复用
   - 步骤：当每次调用selector的时候，需要将监听的socket的文件描述符注册进selector，将此线程挂载到各个socket的等待队列中，并将这个线程阻塞；当其中某一个socket数据来了的时候，会通过dma写入此次socket的内存缓冲区，然后操作系统会将这个进程对应的这个文件的文件描述符状态置为可读，并将此进程从selector对应的socket中全部删除，将这个线程进入就绪状态，当这个线程执行的时候，会遍历此时的所有文件描述符，看哪个来数据了，再去读出来；然后再重新注册进去，循环往复。
   - 缺点：虽然实现了一个线程监听多个socket，但是每次注册需要遍历（把线程注册到每个fd），fd需要从用户态传到内核态，唤醒需要遍历删除socket，线程被唤醒后，还需要遍历一次看哪些fd上有数据，效率很低。
4. epoll：为了优化selector而生的。selector的缺点就是每次都要把fd重新送入监听，并且每次在用户态还需要遍历一遍fd来确定哪些socket接受到了数据，epoll就是在这方面进行了优化。
   - 步骤：使用了eventpoll对象来进行操作，eventpoll对象也是一个文件抽象；
     1. 先通过调用epoll_create创建eventpoll对象，在通过epoll_ctl向eventpoll添加socket，此时这些socket会将epoll对象添加到他们的等待队列中；
     2. 此时调用epoll_wait，会将此时的进程添加到epoll对象的等待队列中，看就绪列表没有数据就阻塞；
     3. 当socket接受到数据的时候，会在epoll对象的就绪列表中添加相应socket的引用，此时epoll对象会唤醒此时的进程，进程直接通过epll对象的就绪列表就能拿到此时收到数据的socket。然后操作完这些就绪列表中的socket数据之后，再调用epoll_wait，循环。
   - 数据结构：
     - 就绪列表必须要快速的插入、删除引用，使用了双向链表。
     - 既然 Epoll 将“维护监视队列”和“进程阻塞”分离，也意味着需要有个数据结构来保存监视的 Socket，至少要方便地添加和移除，还要便于搜索，以避免重复添加。红黑树是一种自平衡二叉查找树，搜索、插入和删除时间复杂度都是 O(log(N))，效率较好。
   - 触发方式：
     - 水平触发：当fd中只要有数据没读完，就通知。
     - 边缘触发：当fd变成就绪态，就通知，只通知一次。
     - epoll的边缘触发只能搭配非阻塞socket使用，因为当边缘触发唤醒后，本质上还是要read各个就绪socket的缓冲区，你对一个socket read完之后有可能还有数据，所以必须再读，但是万一没有数据了，那整个线程就在这个socket上被阻塞了。
5. 零拷贝：不进行内核态到用户态这个步骤，直接从接受缓冲区到另一个发送缓冲区，使用于不需要用户处理的数据。
   - linux使用mmap这类函数实现零拷贝，调用mmap，将文件通过dma传到内核缓冲区中，然后mmap会将内核缓冲区和应用程序缓冲区进行映射，不需要进行拷贝，然后直接调用write到另一个文件的写缓冲区就实现了数据在内核态之间的传递。
   - netty中通过transform实现。
6. java nio：加分项：对java nio的理解：new io、no blocking io





### HTTP

1. 报文组成：请求行+请求头+正文

2. 常见请求头k-v

   1. Accept-Charset：客户端可以识别的字符集
   2. Content-Type：正文格式
   3. Connection:keep-alive  在1.1之后加入这个变成长连接
   4. Cache-control：主要用于缓存的场合，当http服务器（例如nginx）解析出max-age 指令时，如果判定缓存层中存在数据并且max-age比指定缓存时间小，那么就认为能够直接把缓存中的返回客户端，否则会请求应用服务器。

3. 常见状态码

   ![状态码](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E7%8A%B6%E6%80%81%E7%A0%81.png)

4. HTTP1.0：tcp短连接，每次http连接都要开一个新的tcp连接，非常耗时耗资源。

5. HTTP1.1：默认开启keep-alive，一次tcp能传多次http连接。

   1. 普通的tcp长连接：每次处理玩一个http连接才会处理下一个；只要一个阻塞，后面的都会受影响。
   2. pipeline模式：一个请求发送完毕后，无需等待响应，便可发送下一个请求。但是服务端响应的时候只能按照客户端发送请求的顺序进行响应，如果第一个请求处理特别慢，后面的请求即使处理完毕，也要等着，这就是著名的线头阻塞问题。

6. HTTP2.0

   1. 对http请求头进行一定的压缩，建立索引表，每次发头只要发索引即可。

   2. 一个tcp连接传输多个http连接的时候引入了流的概念，说白了就是之前http1.1的时候每次需要tcp把报文排好序传给应用层，所以需要按顺序来；而2.0的时候应用层可以负责对一个流id中的报文的顺序控制工作。

      ![img](https://static001.geekbang.org/resource/image/3d/d3/3da001fac5701949b94e51caaee887d3.jpeg)

7. HTTP3.0了解

8. 各个版本的对比：https://mp.weixin.qq.com/s/amOya0M00LwpL5kCS96Y6w

9. HTTP与HTTPS的区别：http://www.sxyniubi.xyz/archives/https%E5%8A%A0%E5%AF%86%E6%B5%81%E7%A8%8B%E5%92%8C%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5



### MQTT以及一些MQ

http://www.sxyniubi.xyz/archives/%E9%9D%A2%E8%AF%95mqtt%E7%90%86%E8%A7%A3











































